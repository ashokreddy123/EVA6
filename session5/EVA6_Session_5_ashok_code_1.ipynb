{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EVA6 - Session 5_ashok_code_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT60hhKPYC-0"
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                      \n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DU0gF02MJjr"
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M58z98JNayo",
        "outputId": "7495e6f5-9935-4609-8c46-3321de911d8d"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz4RrDxHnl3b"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    \n",
        "    #convolutuonla block 1\n",
        "    self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    )#input_size = 28, #output_size = 26, RF = 3\n",
        "    self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    ) #input_size = 26, #output_size = 24, RF = 5\n",
        "    self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    ) #input_size = 24, #output_size = 22, RF = 7\n",
        "    \n",
        "    # transition block\n",
        "    self.maxpool1 = nn.MaxPool2d(2,2) #input_size = 22, #output_size = 11, RF = 8\n",
        "    self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    )#input_size = 11, #output_size = 9, RF = 12\n",
        "    self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    )#input_size = 9, #output_size = 7, RF = 16\n",
        "\n",
        "    #convolutuonla block 2\n",
        "    self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    )#input_size = 7, #output_size = 5, RF = 20\n",
        "    self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU()\n",
        "    )#input_size = 5, #output_size = 3, RF = 24\n",
        "\n",
        "   #output block\n",
        "    self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=10, kernel_size=(3,3), padding=0, bias=False),\n",
        "            \n",
        "    )#input_size = 3, #output_size = 1, RF = 28\n",
        "\n",
        "  def forward(self,input):\n",
        "\n",
        "    x = self.convblock3(self.convblock2(self.convblock1(input)))\n",
        "\n",
        "    x = self.convblock4(self.maxpool1(x))\n",
        "\n",
        "    x = self.convblock8(self.convblock7(self.convblock6(self.convblock5(x))))\n",
        "\n",
        "  \n",
        "\n",
        "    return F.log_softmax(x)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtQmcB7ZwoYB",
        "outputId": "22d48a1b-26f9-42b7-8ec8-61b3548e8fca"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "              ReLU-2           [-1, 16, 26, 26]               0\n",
            "            Conv2d-3           [-1, 32, 24, 24]           4,608\n",
            "              ReLU-4           [-1, 32, 24, 24]               0\n",
            "            Conv2d-5           [-1, 64, 22, 22]          18,432\n",
            "              ReLU-6           [-1, 64, 22, 22]               0\n",
            "         MaxPool2d-7           [-1, 64, 11, 11]               0\n",
            "            Conv2d-8            [-1, 128, 9, 9]          73,728\n",
            "              ReLU-9            [-1, 128, 9, 9]               0\n",
            "           Conv2d-10            [-1, 256, 7, 7]         294,912\n",
            "             ReLU-11            [-1, 256, 7, 7]               0\n",
            "           Conv2d-12            [-1, 512, 5, 5]       1,179,648\n",
            "             ReLU-13            [-1, 512, 5, 5]               0\n",
            "           Conv2d-14           [-1, 1024, 3, 3]       4,718,592\n",
            "             ReLU-15           [-1, 1024, 3, 3]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]          92,160\n",
            "================================================================\n",
            "Total params: 6,382,224\n",
            "Trainable params: 6,382,224\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.66\n",
            "Params size (MB): 24.35\n",
            "Estimated Total Size (MB): 26.01\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Vfhab8iv_s"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  #pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    #print(\"target size:\",target.size())\n",
        "    #target = target.squeeze(1)\n",
        "    #print(\"target size2:\",target.size())\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "    #print(\"y_pred size:\",y_pred.size())\n",
        "    y_pred = y_pred.squeeze(-1)\n",
        "    y_pred = y_pred.squeeze(-1)\n",
        "    #print(\"y_pred size2:\",y_pred.size())\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    #pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "  return (100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            output = output.squeeze(-1)\n",
        "            output = output.squeeze(-1)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    \"\"\"\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \"\"\"\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    return (100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQp2v2TAi6ps",
        "outputId": "8378c52e-a8c1-46ad-9594-753058d340f4"
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 14\n",
        "for epoch in range(EPOCHS):\n",
        "    #print(\"EPOCH:\", epoch)\n",
        "    train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_accuracy = test(model, device, test_loader)\n",
        "    print(\"epoch no: \",epoch+1,\" train_accuracy: \",train_accuracy,\" test_accuracy: \",test_accuracy)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch no:  1  train_accuracy:  67.98333333333333  test_accuracy:  96.47\n",
            "epoch no:  2  train_accuracy:  97.355  test_accuracy:  97.86\n",
            "epoch no:  3  train_accuracy:  98.32833333333333  test_accuracy:  98.01\n",
            "epoch no:  4  train_accuracy:  98.72833333333334  test_accuracy:  98.81\n",
            "epoch no:  5  train_accuracy:  99.07  test_accuracy:  98.84\n",
            "epoch no:  6  train_accuracy:  99.25666666666666  test_accuracy:  99.13\n",
            "epoch no:  7  train_accuracy:  99.415  test_accuracy:  98.97\n",
            "epoch no:  8  train_accuracy:  99.50333333333333  test_accuracy:  99.05\n",
            "epoch no:  9  train_accuracy:  99.59166666666667  test_accuracy:  99.1\n",
            "epoch no:  10  train_accuracy:  99.62  test_accuracy:  99.1\n",
            "epoch no:  11  train_accuracy:  99.71333333333334  test_accuracy:  99.08\n",
            "epoch no:  12  train_accuracy:  99.76333333333334  test_accuracy:  99.01\n",
            "epoch no:  13  train_accuracy:  99.77  test_accuracy:  99.03\n",
            "epoch no:  14  train_accuracy:  99.75666666666666  test_accuracy:  99.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0yVVuG3gIrS"
      },
      "source": [
        "Target :\n",
        "\n",
        "\n",
        "1.  Setting up the colab file\n",
        "2.   Setting basic working code\n",
        "3. Setting training and testing loop\n",
        "\n",
        "Results :\n",
        "\n",
        "\n",
        "1.  Parameters - 6.38M\n",
        "2.   Best Trai accuracy - 99.77 (within 14 epochs)\n",
        "3.  Best Test accuracy - 99.21\n",
        "\n",
        "Analysis :\n",
        "\n",
        "\n",
        "1.  Overfitting in model\n",
        "2. Training accuracy would have been higher if trained for higher epochs\n",
        "3. Model is heavy for recognising digits. Need to decrease parameters.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6DaehlFiUCp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}